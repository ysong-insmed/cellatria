# stndrd_analysis.py
# -------------------------------

import os
import sys
import scanpy as sc
import harmonypy as hm
import numpy as np
from helper import parse_vars, graph_pipeline, _ensure_counts_matrix, _prepare_scvi_adata

# -------------------------------

def run_analysis(adata, args):
    """
    Runs the standard Scanpy single-cell analysis pipeline, including normalization,
    variable gene selection, scaling, PCA, optional regression and batch correction,
    clustering, and dimensionality reduction (UMAP, optionally TSNE).

    The function also preserves:
      - raw counts (for annotation),
      - normalized counts (for visualization & DEA),
      - scaled data (for PCA/clustering),
      - harmonized and non-harmonized versions (if batch correction is enabled).

    Args:
        adata (AnnData): Combined AnnData object after sample merging.
        args (Namespace): Parsed command-line arguments including normalization, 
                          batch correction, PCA, clustering, and regression settings.

    Returns:
        tuple:
            - raw_counts (AnnData): Copy of unmodified input counts (for cell annotation).
            - adata (AnnData): Processed and optionally batch-corrected dataset.
            - adata_nohm (AnnData or None): Non-harmonized version (if batch correction applied).
    """

    # -------------------------------
    # 0. Store Raw Data (preprocessing snapshot)
    # This preserves the raw expression for celltype annotation later
    raw_counts = adata.copy()
    _ensure_counts_matrix(raw_counts)  # normalize dtype/format up front  

    # -------------------------------
    # 1. Normalization (log1p)
    print("*** ðŸ”„ Normalizing data (log1p)...")
    sc.pp.normalize_total(adata, target_sum=args.norm_target_sum) # (default 10,000 UMIs per cell)
    sc.pp.log1p(adata)

    # -------------------------------
    # 2. HVG Selection
    print("*** ðŸ”„ Selecting highly variable genes...")
    sc.pp.highly_variable_genes(adata, flavor='seurat', n_top_genes=args.n_top_genes)

    # -------------------------------
    # 3. Preserve Log-Normalized Data
    adata.raw = adata.copy() # Log1p-normalized counts saved for visualization/DEA

    # -------------------------------
    # 4. Filter dataset to only keep highly variable genes (can be skipped if desired)
    hvg_mask = adata.var["highly_variable"].values
    # adata = adata[:, hvg_mask].copy()

    # -------------------------------
    # 5. Regress Out Technical Effects (optional)
    # Regress out total counts and mitochondrial percentage to remove technical bias.
    # It requires dense data, so it can be expensive on large datasets.
    if args.regress_out.lower() == "yes":
        print("*** ðŸ”„ Regressing out total counts and pct_counts_mito...")
        sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mito'])
    else:
        print("*** ðŸš« Skipping regression step (per user input).")

    # -------------------------------

    # 8. Batch Correction
    # Initialize adata_nohm to None â€” this will be returned if no batch correction happens
    adata_nohm = None
    bc = (getattr(args, "batch_correction", None) or "").lower()

    if bc == "harmony": 

        btchvrs = parse_vars(args.batch_vars) # Parse and validate vars_batch (comma-separated columns).        
        missing_vars = [var for var in btchvrs if var not in adata.obs.columns] # Ensure all specified columns exist in adata.obs.
        if missing_vars:
            raise ValueError(f"*** ðŸš¨ The following columns specified in --batch_vars are missing from adata.obs: {', '.join(missing_vars)}")        

        adata_nohm = adata.copy() # Store a copy of adata before batch correction

        # Perform Harmony batch correction

        # first re-select HVGs
        # Convert to categorical
        if len(btchvrs) == 1:
            adata.obs[btchvrs[0]] = adata.obs[btchvrs[0]].astype("category")
            print("*** ðŸ”„ Re-selecting highly variable genes before Harmony...")
            sc.pp.highly_variable_genes(adata, flavor='seurat', n_top_genes=args.n_top_genes, batch_key=btchvrs[0])
            # -------------------------------
            # 6. Scaling, need to happen on log1p data so here
            print(f"*** ðŸ”„ Scaling data with max_value={args.scale_max_value}...")
            sc.pp.scale(adata, max_value=args.scale_max_value)

            # -------------------------------
            # 7. Principal Component Analysis (PCA), need to happen on scaled data, use newly selected HVGs
            print(f"*** ðŸ”„ Running PCA with {args.n_pcs} components...")
            sc.tl.pca(adata, svd_solver="arpack", n_comps=args.n_pcs, use_highly_variable=True)

        print(f"*** ðŸ”„ Performing batch correction using Harmony on: {' and '.join(btchvrs)} ...")
        harmony_out = hm.run_harmony(adata.obsm['X_pca'], adata.obs, btchvrs)

        adata.obsm['X_pca'] = harmony_out.Z_corr # Replace PCA embeddings in adata with Harmony-corrected version
        print("*** âœ… Harmony correction complete.")
    
    elif bc == "scvi":

        import scvi
        
        btchvrs = parse_vars(args.batch_vars)
        if len(btchvrs) > 1: # scVI uses a single batch key
            raise ValueError(f"*** ðŸš¨ scVI only supports a single batch variable. You provided: {', '.join(btchvrs)}")
        bkey = btchvrs[0] if btchvrs else None
        if bkey not in adata.obs.columns:
            raise ValueError(f"*** ðŸš¨ The batch variable '{bkey}' is not present in adata.obs. Available columns: {', '.join(adata.obs.columns)}")

        adata_nohm = adata.copy() # Store a copy of adata before batch correction
        
        print("*** ðŸ”„ Training scVI on counts (CPU-friendly settings)...")        
        scvi_adata = _prepare_scvi_adata(raw_counts, hvg_mask, bkey)
        scvi.model.SCVI.setup_anndata(scvi_adata, batch_key=bkey)
        model = scvi.model.SCVI(scvi_adata, n_latent=args.n_pcs)
        model.train(
            max_epochs=30,
            check_val_every_n_epoch=None,
            early_stopping=True,
            enable_progress_bar=True
        )
        # Latent â†’ main AnnData (same cell order, since we didnâ€™t drop cells)
        adata.obsm["X_scVI"] = model.get_latent_representation()
        print("*** âœ… scVI correction complete.")

    else:
        print("*** ðŸš« No batch correction applied (per user input).")

    # -------------------------------
    # 9. Neighborhood graph, UMAP, TSNE, and clustering
    graph_pipeline(adata, args)

    # Run for non-harmonized data if available
    if adata_nohm is not None:
        print("*** ðŸ”„ Processing non-harmonized (original) data...")
        # -------------------------------
        # 6. Scaling
        print(f"*** ðŸ”„ Scaling data with max_value={args.scale_max_value}...")
        sc.pp.scale(adata_nohm, max_value=args.scale_max_value)

        # -------------------------------
        # 7. Principal Component Analysis (PCA)
        print(f"*** ðŸ”„ Running PCA with {args.n_pcs} components...")
        sc.tl.pca(adata_nohm, svd_solver="arpack", n_comps=args.n_pcs, use_highly_variable=True)

        graph_pipeline(adata_nohm, args, label = "no batch corrected")

    # -------------------------------
    print("*** âœ… Standard analysis pipeline completed.")
    return raw_counts, adata, adata_nohm